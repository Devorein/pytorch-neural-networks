{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMa_L4CSqYsf"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "xHMY7YmX7xCl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "def train_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, optimizer: torch.optim, acc_fn, loss_fn: torch.nn.Module, device=\"cpu\"):\n",
        "  train_loss_cum = 0\n",
        "  train_acc_cum = 0\n",
        "  train_start_time = timer()\n",
        "  model.train()\n",
        "  for train_batch_number, (train_features, train_labels) in enumerate(data_loader):\n",
        "    train_features = train_features.to(device)\n",
        "    train_labels = train_labels.to(device)\n",
        "\n",
        "    train_pred_labels = model(train_features)\n",
        "\n",
        "    train_loss = loss_fn(train_pred_labels, train_labels)\n",
        "\n",
        "    train_loss_cum += train_loss.item()\n",
        "    train_acc_cum += acc_fn(train_pred_labels.argmax(dim=1), train_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if train_batch_number % 500 == 0:\n",
        "      print(f\"Looked at {train_batch_number * len(train_features)}/{len(data_loader) * len(train_features)} samples\")\n",
        "\n",
        "  train_loss = train_loss_cum / len(data_loader)\n",
        "  train_acc = train_acc_cum / len(data_loader)\n",
        "  train_end_time = timer()\n",
        "  train_total_time = train_end_time - train_start_time\n",
        "  return {\n",
        "      \"train_loss\": train_loss,\n",
        "      \"train_acc\": train_acc,\n",
        "      \"train_total_time\": train_total_time\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "tLqubK_J50kd"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, acc_fn, loss_fn: torch.nn.Module, device=\"cpu\"):\n",
        "  eval_loss_cum = 0\n",
        "  eval_acc_cum = 0\n",
        "  eval_start_time = timer()\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for eval_batch_number, (eval_features, eval_labels) in enumerate(data_loader):\n",
        "      eval_features = eval_features.to(device)\n",
        "      eval_labels = eval_labels.to(device)\n",
        "      eval_pred_labels = model(eval_features)\n",
        "      eval_loss_cum += loss_fn(eval_pred_labels, eval_labels)\n",
        "      eval_acc_cum += acc_fn(eval_pred_labels.argmax(dim=1), eval_labels)\n",
        "\n",
        "  eval_loss = eval_loss_cum / len(data_loader)\n",
        "  eval_acc = eval_acc_cum / len(data_loader)\n",
        "  eval_end_time = timer()\n",
        "  eval_total_time = eval_end_time - eval_start_time\n",
        "  return {\n",
        "      \"eval_total_time\": eval_total_time,\n",
        "      \"eval_loss\": eval_loss,\n",
        "      \"eval_acc\": eval_acc\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Rsw4Sa4pr-tG"
      },
      "outputs": [],
      "source": [
        "## Creating a training loop and training model in batches of data rather than epoch\n",
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer as timer\n",
        "import torch\n",
        "from torchmetrics import Accuracy\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_eval_loop(model: torch.nn.Module, train_data: torch.utils.data.Dataset, test_data: torch.utils.data.Dataset, random_state: int=42, device: str=\"cpu\", lr: float=0.01, batch_size: int=32, epochs: int=10):\n",
        "\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  optimizer = torch.optim.SGD(params=model.parameters(), lr=lr)\n",
        "\n",
        "  acc_fn = Accuracy(task=\"multiclass\", num_classes=len(train_data.classes)).to(device)\n",
        "\n",
        "  torch.manual_seed(random_state)\n",
        "  if device == \"cuda\":\n",
        "    torch.cuda.manual_seed(random_state)\n",
        "\n",
        "  train_dataloader = DataLoader(\n",
        "      train_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "  )\n",
        "\n",
        "  eval_dataloader = DataLoader(\n",
        "      test_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "  )\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch + 1} -----\")\n",
        "    \n",
        "    train_data = train_model(\n",
        "        model=model,\n",
        "        data_loader=train_dataloader,\n",
        "        acc_fn=acc_fn,\n",
        "        loss_fn=loss_fn,\n",
        "        device=device,\n",
        "        optimizer=optimizer\n",
        "    )\n",
        "    print(f'''train time on {device}: {train_data[\"train_total_time\"]:.4f} seconds''')\n",
        "\n",
        "    eval_data = eval_model(\n",
        "        model=model,\n",
        "        data_loader=eval_dataloader,\n",
        "        acc_fn=acc_fn,\n",
        "        loss_fn=loss_fn,\n",
        "        device=device\n",
        "    )\n",
        "    print(f'''eval time on {device}: {eval_data[\"eval_total_time\"]:.4f} seconds''')\n",
        "\n",
        "    print(f'''Train loss: {train_data[\"train_loss\"]:.4f} | Train accuracy: {train_data[\"train_acc\"]:.2f}% | Eval loss: {eval_data[\"eval_loss\"]:.4f} | Eval accuracy: {eval_data[\"eval_acc\"]:.2f}%''')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "train_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor(), target_transform=None)\n",
        "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor(), target_transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNb_rnXJrgAG"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# NN without any non-linear activation function\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(\n",
        "            in_features=input_shape,\n",
        "            out_features=hidden_units\n",
        "        ),\n",
        "        nn.Linear(\n",
        "            in_features=hidden_units,\n",
        "            out_features=output_shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.layers(x)\n",
        "\n",
        "  \n",
        "  for device in [\"cpu\", \"cuda\"]:\n",
        "    train_eval_loop(\n",
        "        FashionMNISTModelV0(\n",
        "          input_shape=28 * 28,\n",
        "          output_shape=len(train_data.classes),\n",
        "          hidden_units=10\n",
        "        ),\n",
        "        train_data=train_data,\n",
        "        test_data=test_data,\n",
        "        epochs=5,\n",
        "        device=device\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Model with non-linear activation functions\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(\n",
        "            in_features=input_shape,\n",
        "            out_features=hidden_units\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(\n",
        "            in_features=hidden_units,\n",
        "            out_features=output_shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.layers(x)\n",
        "\n",
        "  from torch import nn\n",
        "\n",
        "\n",
        "for device in [\"cpu\", \"cuda\"]:\n",
        "  train_eval_loop(\n",
        "      FashionMNISTModelV1(\n",
        "        input_shape=28 * 28,\n",
        "        output_shape=len(train_data.classes),\n",
        "        hidden_units=10\n",
        "      ),\n",
        "      train_data=train_data,\n",
        "      test_data=test_data,\n",
        "      epochs=5,\n",
        "      device=device\n",
        "  )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
