{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMa_L4CSqYsf"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "xHMY7YmX7xCl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "def train_step(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, optimizer: torch.optim, accuracy_fn, loss_fn: torch.nn.Module, device=\"cpu\"):\n",
        "  train_loss_cum = 0\n",
        "  train_accuracy_cum = 0\n",
        "  train_start_time = timer()\n",
        "  model.train()\n",
        "  for train_batch_number, (train_features, train_labels) in enumerate(data_loader):\n",
        "    train_features = train_features.to(device)\n",
        "    train_labels = train_labels.to(device)\n",
        "\n",
        "    train_pred_labels = model(train_features)\n",
        "\n",
        "    train_loss = loss_fn(train_pred_labels, train_labels)\n",
        "\n",
        "    train_loss_cum += train_loss.item()\n",
        "    train_accuracy_cum += accuracy_fn(train_pred_labels.argmax(dim=1), train_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if train_batch_number % 500 == 0:\n",
        "      print(f\"Looked at {train_batch_number * len(train_features)}/{len(data_loader) * len(train_features)} samples\")\n",
        "\n",
        "  train_loss = train_loss_cum / len(data_loader)\n",
        "  train_accuracy = train_accuracy_cum / len(data_loader)\n",
        "  train_end_time = timer()\n",
        "  train_total_time = train_end_time - train_start_time\n",
        "  return {\n",
        "      \"train_loss\": train_loss,\n",
        "      \"train_accuracy\": train_accuracy,\n",
        "      \"train_total_time\": train_total_time\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "tLqubK_J50kd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "def test_step(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, accuracy_fn, loss_fn: torch.nn.Module, device=\"cpu\"):\n",
        "  test_loss_cum = 0\n",
        "  test_accuracy_cum = 0\n",
        "  test_start_time = timer()\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for test_batch_number, (test_features, test_labels) in enumerate(data_loader):\n",
        "      test_features = test_features.to(device)\n",
        "      test_labels = test_labels.to(device)\n",
        "      test_pred_labels = model(test_features)\n",
        "      test_loss_cum += loss_fn(test_pred_labels, test_labels)\n",
        "      test_accuracy_cum += accuracy_fn(test_pred_labels.argmax(dim=1), test_labels)\n",
        "\n",
        "  test_loss = test_loss_cum / len(data_loader)\n",
        "  test_accuracy = test_accuracy_cum / len(data_loader)\n",
        "  test_end_time = timer()\n",
        "  test_total_time = test_end_time - test_start_time\n",
        "  return {\n",
        "      \"test_total_time\": test_total_time,\n",
        "      \"test_loss\": test_loss,\n",
        "      \"test_accuracy\": test_accuracy\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Rsw4Sa4pr-tG"
      },
      "outputs": [],
      "source": [
        "## Creating a training loop and training model in batches of data rather than epoch\n",
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer as timer\n",
        "import torch\n",
        "from torchmetrics import Accuracy\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_test_loop(model: torch.nn.Module, train_data: torch.utils.data.Dataset, test_data: torch.utils.data.Dataset, random_state: int=42, device: str=\"cpu\", lr: float=0.01, batch_size: int=32, epochs: int=10):\n",
        "\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  optimizer = torch.optim.SGD(params=model.parameters(), lr=lr)\n",
        "\n",
        "  accuracy_fn = Accuracy(task=\"multiclass\", num_classes=len(train_data.classes)).to(device)\n",
        "\n",
        "  torch.manual_seed(random_state)\n",
        "  if device == \"cuda\":\n",
        "    torch.cuda.manual_seed(random_state)\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  train_model = False\n",
        "  test_modal = False\n",
        "\n",
        "  if train_data is not None:\n",
        "    train_model = True\n",
        "    train_dataloader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "  if test_data is not None:\n",
        "    test_model = True\n",
        "    test_dataloader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch + 1} -----\")\n",
        "\n",
        "    epoch_data = {\n",
        "      \"train_loss\": None,\n",
        "      \"train_accuracy\": None,\n",
        "      \"test_loss\": None,\n",
        "      \"test_accuracy\": None,\n",
        "    }\n",
        "\n",
        "    if train_model:\n",
        "      train_data = train_step(\n",
        "          model=model,\n",
        "          data_loader=train_dataloader,\n",
        "          accuracy_fn=accuracy_fn,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device,\n",
        "          optimizer=optimizer\n",
        "      )\n",
        "      epoch_data[\"train_loss\"] = train_data[\"train_loss\"]\n",
        "      epoch_data[\"train_accuracy\"] = train_data[\"train_accuracy\"]\n",
        "      print(f'''train time on {device}: {train_data[\"train_total_time\"]:.4f} seconds''')\n",
        "\n",
        "    if test_model:\n",
        "      test_data = test_step(\n",
        "          model=model,\n",
        "          data_loader=test_dataloader,\n",
        "          accuracy_fn=accuracy_fn,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device\n",
        "      )\n",
        "      epoch_data[\"test_loss\"] = test_data[\"test_loss\"]\n",
        "      epoch_data[\"test_accuracy\"] = test_data[\"test_accuracy\"]\n",
        "      print(f'''test time on {device}: {test_data[\"test_total_time\"]:.4f} seconds''')\n",
        "\n",
        "    output_info = []\n",
        "    if epoch_data[\"train_loss\"] is not None:\n",
        "      output_info.append(\n",
        "        f'''Train loss: {epoch_data[\"train_loss\"]:.4f}'''\n",
        "      )\n",
        "\n",
        "    if epoch_data[\"train_accuracy\"] is not None:\n",
        "      output_info.append(\n",
        "        f'''Train accuracy: {epoch_data[\"train_accuracy\"]:.2f}%'''\n",
        "      )\n",
        "\n",
        "    if epoch_data[\"test_loss\"] is not None:\n",
        "      output_info.append(\n",
        "        f'''Test loss: {epoch_data[\"test_loss\"]:.4f}'''\n",
        "      )\n",
        "\n",
        "    if epoch_data[\"test_accuracy\"] is not None:\n",
        "      output_info.append(\n",
        "        f'''Test accuracy: {epoch_data[\"test_accuracy\"]:.2f}%'''\n",
        "      )\n",
        "\n",
        "    if len(output_info) != 0:\n",
        "      print(\" | \".join(output_info))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "train_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor(), target_transform=None)\n",
        "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor(), target_transform=None)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNb_rnXJrgAG"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# NN without any non-linear activation function\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(\n",
        "            in_features=input_shape,\n",
        "            out_features=hidden_units\n",
        "        ),\n",
        "        nn.Linear(\n",
        "            in_features=hidden_units,\n",
        "            out_features=output_shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.layers(x)\n",
        "\n",
        "  \n",
        "train_test_loop(\n",
        "    FashionMNISTModelV0(\n",
        "      input_shape=28 * 28,\n",
        "      output_shape=len(train_data.classes),\n",
        "      hidden_units=10\n",
        "    ),\n",
        "    train_data=train_data,\n",
        "    test_data=test_data,\n",
        "    epochs=5,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "# Model with non-linear activation functions\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(\n",
        "            in_features=input_shape,\n",
        "            out_features=hidden_units\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(\n",
        "            in_features=hidden_units,\n",
        "            out_features=output_shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.layers(x)\n",
        "\n",
        "  from torch import nn\n",
        "\n",
        "\n",
        "train_test_loop(\n",
        "    FashionMNISTModelV1(\n",
        "      input_shape=28 * 28,\n",
        "      output_shape=len(train_data.classes),\n",
        "      hidden_units=10\n",
        "    ),\n",
        "    train_data=train_data,\n",
        "    test_data=test_data,\n",
        "    epochs=5,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FashionMNISTModelV2(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=input_shape,\n",
        "            out_channels=hidden_units,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units,\n",
        "            out_channels=hidden_units,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units,\n",
        "            out_channels=hidden_units,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units,\n",
        "            out_channels=hidden_units,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(\n",
        "            in_features=hidden_units * 7 * 7,\n",
        "            out_features=output_shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "\n",
        "    return self.classifier(x)\n",
        "\n",
        "train_test_loop(\n",
        "    FashionMNISTModelV2(\n",
        "      input_shape=1,\n",
        "      output_shape=len(train_data.classes),\n",
        "      hidden_units=10\n",
        "    ),\n",
        "    train_data=train_data,\n",
        "    test_data=test_data,\n",
        "    epochs=5,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ae98a2d7cb2d0c57cfbbd7d812947b84707417a4702cc81eb8890c9224ec2f85"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
